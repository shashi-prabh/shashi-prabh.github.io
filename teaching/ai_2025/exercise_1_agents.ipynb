{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent Agents #\n",
    "\n",
    "This notebook serves as supporting material for topics covered in **Chapter 2 - Intelligent Agents** from the book *Artificial Intelligence: A Modern Approach.* This notebook uses implementations from [agents.py](https://github.com/aimacode/aima-python/blob/master/agents.py) module. Let's start by importing everything from agents module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Robot Wave](https://media1.giphy.com/media/v1.Y2lkPTc5MGI3NjExNHJ1eHQ1aWxqM2xyZzA0a3Z6bDJyMmFweGsxeHBhM3Z5NHUwenZraSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/5k5vZwRFZR5aZeniqb/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import *\n",
    "from notebook import psource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONTENTS\n",
    "    \n",
    "* Overview\n",
    "* Agent\n",
    "* Environment\n",
    "* Exercise 1\n",
    "* Blind Dog\n",
    "* Energetic Blind Dog\n",
    "* Exercise 2\n",
    "\n",
    "## OVERVIEW\n",
    "\n",
    "An agent, as defined in 2.1, is anything that can perceive its <b>environment</b> through sensors, and act upon that environment through actuators based on its <b>agent program</b>. This can be a dog, a robot, or even you. As long as you can perceive the environment and act on it, you are an agent. This notebook will explain how to implement a simple agent, create an environment, and implement a program that helps the agent act on the environment based on its percepts.\n",
    "\n",
    "## AGENT\n",
    "\n",
    "Let us now see how we define an agent. Run the next cell to see how `Agent` is defined in agents module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(Agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Agent` has two methods.\n",
    "* `__init__(self, program=None)`: The constructor defines various attributes of the Agent. These include\n",
    "\n",
    "    * `alive`: which keeps track of whether the agent is alive or not \n",
    "    \n",
    "    * `bump`: which tracks if the agent collides with an edge of the environment (for eg, a wall in a park)\n",
    "    \n",
    "    * `holding`: which is a list containing the `Things` an agent is holding, \n",
    "    \n",
    "    * `performance`: which evaluates the performance metrics of the agent \n",
    "    \n",
    "    * `program`: which is the agent program and maps an agent's percepts to actions in the environment. If no implementation is provided, it defaults to asking the user to provide actions for each percept.\n",
    "    \n",
    "* `can_grab(self, thing)`: Is used when an environment contains things that an agent can grab and carry. By default, an agent can carry nothing.\n",
    "\n",
    "## ENVIRONMENT\n",
    "Now, let us see how environments are defined. Running the next cell will display an implementation of the abstract `Environment` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(Environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Environment` class has lot of methods! But most of them are incredibly simple, so let's see the ones we'll be using in this notebook.\n",
    "\n",
    "* `thing_classes(self)`: Returns a static array of `Thing` sub-classes that determine what things are allowed in the environment and what aren't\n",
    "\n",
    "* `add_thing(self, thing, location=None)`: Adds a thing to the environment at location\n",
    "\n",
    "* `run(self, steps)`: Runs an environment with the agent in it for a given number of steps.\n",
    "\n",
    "* `is_done(self)`: Returns true if the objective of the agent and the environment has been completed\n",
    "\n",
    "The next two functions must be implemented by each subclasses of `Environment` for the agent to recieve percepts and execute actions \n",
    "\n",
    "* `percept(self, agent)`: Given an agent, this method returns a list of percepts that the agent sees at the current time\n",
    "\n",
    "* `execute_action(self, agent, action)`: The environment reacts to an action performed by a given agent. The changes may result in agent experiencing new percepts or other elements reacting to agent input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Vacuum-World Agent (Table-Driven Agent)\n",
    "\n",
    "1. Run and understand the following implementation of a table-driven vacuum-world agent\n",
    "2. Change the code such that the rooms get dirty again after 1 time step (if you wish, you can choose a random interval between 1 and 2 steps)\n",
    "3. Make necessay changes to the code such that the agent runs for at-least 4 time staeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent,Thing\n",
    "import random\n",
    "import numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \"\"\"Abstract class representing an Environment. 'Real' Environment classes\n",
    "    inherit from this. Your Environment will typically need to implement:\n",
    "        percept:           Define the percept that an agent sees.\n",
    "        execute_action:    Define the effects of executing an action.\n",
    "                           Also update the agent.performance slot.\n",
    "    The environment keeps a list of .things and .agents (which is a subset\n",
    "    of .things). Each agent has a .performance slot, initialized to 0.\n",
    "    Each thing has a .location slot, even though some environments may not\n",
    "    need this.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.things = []\n",
    "        self.agents = []\n",
    "\n",
    "    def thing_classes(self):\n",
    "        return []  # List of classes that can go into environment\n",
    "\n",
    "    def percept(self, agent):\n",
    "        \"\"\"Return the percept that the agent sees at this point. (Implement this.)\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        \"\"\"Change the world to reflect this action. (Implement this.)\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def default_location(self, thing):\n",
    "        \"\"\"Default location to place a new thing with unspecified location.\"\"\"\n",
    "        return None\n",
    "\n",
    "    def exogenous_change(self):\n",
    "        \"\"\"If there is spontaneous change in the world, override this.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def is_done(self):\n",
    "        \"\"\"By default, we're done when we can't find a live agent.\"\"\"\n",
    "        return not any(agent.is_alive() for agent in self.agents)\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Run the environment for one time step. If the\n",
    "        actions and exogenous changes are independent, this method will\n",
    "        do. If there are interactions between them, you'll need to\n",
    "        override this method.\"\"\"\n",
    "        print(\"Status of enviorment is: \",self.status)\n",
    "        if not self.is_done():\n",
    "            actions = []\n",
    "            for agent in self.agents:\n",
    "                if agent.alive:\n",
    "                    actions.append(agent.program(self.percept(agent)))\n",
    "                else:\n",
    "                    actions.append(\"\")\n",
    "            for (agent, action) in zip(self.agents, actions):\n",
    "                self.execute_action(agent, action)\n",
    "               \n",
    "            self.exogenous_change()\n",
    "\n",
    "    def run(self, steps=1000):\n",
    "        \"\"\"Run the Environment for given number of time steps.\"\"\"\n",
    "        for step in range(steps):\n",
    "            if self.is_done():\n",
    "                return\n",
    "            print()\n",
    "            self.step()\n",
    "\n",
    "\n",
    "    def list_things_at(self, location, tclass=Thing):\n",
    "        \"\"\"Return all things exactly at a given location.\"\"\"\n",
    "        if isinstance(location, numbers.Number):\n",
    "            return [thing for thing in self.things\n",
    "                    if thing.location == location and isinstance(thing, tclass)]\n",
    "        return [thing for thing in self.things\n",
    "                if all(x == y for x, y in zip(thing.location, location)) and isinstance(thing, tclass)]\n",
    "\n",
    "    def some_things_at(self, location, tclass=Thing):\n",
    "        \"\"\"Return true if at least one of the things at location\n",
    "        is an instance of class tclass (or a subclass).\"\"\"\n",
    "        return self.list_things_at(location, tclass) != []\n",
    "\n",
    "    def add_thing(self, thing, location=None):\n",
    "        \"\"\"Add a thing to the environment, setting its location. For\n",
    "        convenience, if thing is an agent program we make a new agent\n",
    "        for it. (Shouldn't need to override this.)\"\"\"\n",
    "        if not isinstance(thing, Thing):\n",
    "            thing = Agent(thing)\n",
    "        if thing in self.things:\n",
    "            print(\"Can't add the same thing twice\")\n",
    "        else:\n",
    "            thing.location = location if location is not None else self.default_location(thing)\n",
    "            self.things.append(thing)\n",
    "            if isinstance(thing, Agent):\n",
    "                thing.performance = 0\n",
    "                self.agents.append(thing)\n",
    "        print(\"location of agent is: \",thing.location)\n",
    "\n",
    "    def delete_thing(self, thing):\n",
    "        \"\"\"Remove a thing from the environment.\"\"\"\n",
    "        try:\n",
    "            self.things.remove(thing)\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            print(\"  in Environment delete_thing\")\n",
    "            print(\"  Thing to be removed: {} at {}\".format(thing, thing.location))\n",
    "            print(\"  from list: {}\".format([(thing, thing.location) for thing in self.things]))\n",
    "        if thing in self.agents:\n",
    "            self.agents.remove(thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrivialVacuumEnvironment(Environment):\n",
    "    \"\"\"This environment has two locations, A and B. Each can be Dirty\n",
    "    or Clean. The agent perceives its location and the location's\n",
    "    status. This serves as an example of how to implement a simple\n",
    "    Environment.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.status = {loc_A: random.choice(['Clean', 'Dirty']),\n",
    "                       loc_B: random.choice(['Clean', 'Dirty'])}\n",
    "\n",
    "    def thing_classes(self):\n",
    "        return [TableDrivenVacuumAgent]\n",
    "\n",
    "    def percept(self, agent):\n",
    "        \"\"\"Returns the agent's location, and the location status (Dirty/Clean).\"\"\"\n",
    "        print(\"Agent percepts: \",agent.location,self.status[agent.location])\n",
    "        return agent.location, self.status[agent.location]\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        \"\"\"Change agent's location and/or location's status; track performance.\n",
    "        Score 10 for each dirt cleaned; -1 for each move.\"\"\"\n",
    "        print(f\"Agent is executing {action} at {agent.location}\")\n",
    "        \n",
    "        if action == 'Right':\n",
    "            agent.location = loc_B\n",
    "            agent.performance -= 1\n",
    "        elif action == 'Left':\n",
    "            agent.location = loc_A\n",
    "            agent.performance -= 1\n",
    "        elif action == 'Suck':\n",
    "            if self.status[agent.location] == 'Dirty':\n",
    "                agent.performance += 10\n",
    "            self.status[agent.location] = 'Clean'\n",
    "            \n",
    "        print(f\"Agent's performance is {agent.performance}\")\n",
    "\n",
    "    def default_location(self, thing):\n",
    "        \"\"\"Agents start in either location at random.\"\"\"\n",
    "        location = random.choice([loc_A, loc_B])\n",
    "        return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TableDrivenAgentProgram(table):\n",
    "    \"\"\"\n",
    "    [Figure 2.7]\n",
    "    This agent selects an action based on the percept sequence.\n",
    "    It is practical only for tiny domains.\n",
    "    To customize it, provide as table a dictionary of all\n",
    "    {percept_sequence:action} pairs.\n",
    "    \"\"\"\n",
    "    percepts = []\n",
    "\n",
    "    def program(percept):\n",
    "        percepts.append(percept)\n",
    "        action = table.get(tuple(percepts))\n",
    "        if action is None:\n",
    "            print(\"****Error: No action given in table for this percept****\")\n",
    "        return action\n",
    "\n",
    "    return program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def TableDrivenVacuumAgent():\n",
    "    \"\"\"Tabular approach towards vacuum world as mentioned in [Figure 2.3]\n",
    "    >>> agent = TableDrivenVacuumAgent()\n",
    "    >>> environment = TrivialVacuumEnvironment()\n",
    "    >>> environment.add_thing(agent)\n",
    "    >>> environment.run()\n",
    "    >>> environment.status == {(1,0):'Clean' , (0,0) : 'Clean'}\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    loc_A = (0,0)\n",
    "    loc_B = (1,0)\n",
    "\n",
    "    #Edit this table \n",
    "    table = {\n",
    "            #All one percept possibilities\n",
    "            ((loc_A, 'Clean'),): 'Right',\n",
    "             ((loc_A, 'Dirty'),): 'Suck',\n",
    "             ((loc_B, 'Clean'),): 'Left',\n",
    "             ((loc_B, 'Dirty'),): 'Suck',\n",
    "\n",
    "            #All two percept possibilities\n",
    "             ((loc_A, 'Dirty'), (loc_A, 'Clean')): 'Right',\n",
    "             ((loc_A, 'Clean'), (loc_B, 'Dirty')): 'Suck',\n",
    "             ((loc_B, 'Clean'), (loc_A, 'Dirty')): 'Suck',\n",
    "             ((loc_B, 'Dirty'), (loc_B, 'Clean')): 'Left',\n",
    "\n",
    "             #Complete the list of three percept possibilities\n",
    "            ((loc_A, 'Dirty'), (loc_A, 'Clean'), (loc_B, 'Dirty')): 'Suck',\n",
    "            ((loc_A, 'Dirty'), (loc_A, 'Clean'), (loc_B, 'Clean')): 'Left',\n",
    "            \n",
    "\n",
    "            #add possibilites for 4 percepts here\n",
    "        \n",
    "        }\n",
    "    \n",
    "    return Agent(TableDrivenAgentProgram(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = TableDrivenVacuumAgent() #initializes Table driven vaccuum agent\n",
    "env = TrivialVacuumEnvironment() #Builds the vacuum environment\n",
    "\n",
    "env.add_thing(agent)\n",
    "\n",
    "env.run(4) #Modify the number inside run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMPLE AGENT AND ENVIRONMENT\n",
    "\n",
    "Let's begin by using the `Agent` class to creating our first agent - a blind dog.\n",
    "\n",
    "Run and understand the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlindDog(Agent):\n",
    "    def eat(self, thing):\n",
    "        print(\"Dog: Ate food at {}.\".format(self.location))\n",
    "            \n",
    "    def drink(self, thing):\n",
    "        print(\"Dog: Drank water at {}.\".format( self.location))\n",
    "\n",
    "dog = BlindDog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have just done is create a dog who can only feel what's in his location (since he's blind), and can eat or drink. Let's see if he's alive..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dog.alive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cool dog](https://gifgun.files.wordpress.com/2015/07/wpid-wp-1435860392895.gif)\n",
    "This is our dog. How cool is he? Well, he's hungry and needs to go search for food. For him to do this, we need to give him a program. But before that, let's create a park for our dog to play in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENVIRONMENT - Park\n",
    "\n",
    "A park is an example of an environment because our dog can perceive and act upon it. The <b>Environment</b> class is an abstract class, so we will have to create our own subclass from it before we can use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Food(Thing):\n",
    "    pass\n",
    "\n",
    "class Water(Thing):\n",
    "    pass\n",
    "\n",
    "class Park(Environment):\n",
    "    def percept(self, agent):\n",
    "        '''return a list of things that are in our agent's location'''\n",
    "        things = self.list_things_at(agent.location)\n",
    "        return things\n",
    "    \n",
    "    def execute_action(self, agent, action):\n",
    "        '''changes the state of the environment based on what the agent does.'''\n",
    "        if action == \"move down\":\n",
    "            print('{} decided to {} at location: {}'.format(str(agent)[1:-1], action, agent.location))\n",
    "            agent.movedown()\n",
    "        elif action == \"eat\":\n",
    "            items = self.list_things_at(agent.location, tclass=Food)\n",
    "            if len(items) != 0:\n",
    "                if agent.eat(items[0]): #Have the dog eat the first item\n",
    "                    print('{} ate {} at location: {}'\n",
    "                          .format(str(agent)[1:-1], str(items[0])[1:-1], agent.location))\n",
    "                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "        elif action == \"drink\":\n",
    "            items = self.list_things_at(agent.location, tclass=Water)\n",
    "            if len(items) != 0:\n",
    "                if agent.drink(items[0]): #Have the dog drink the first item\n",
    "                    print('{} drank {} at location: {}'\n",
    "                          .format(str(agent)[1:-1], str(items[0])[1:-1], agent.location))\n",
    "                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "\n",
    "    def is_done(self):\n",
    "        '''By default, we're done when we can't find a live agent, \n",
    "        but to prevent killing our cute dog, we will stop before itself - when there is no more food or water'''\n",
    "        no_edibles = not any(isinstance(thing, Food) or isinstance(thing, Water) for thing in self.things)\n",
    "        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "        return dead_agents or no_edibles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROGRAM - BlindDog\n",
    "Now that we have a <b>Park</b> Class, we re-implement our <b>BlindDog</b> to be able to move down and eat food or drink water only if it is present.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlindDog(Agent):\n",
    "    location = 1\n",
    "    \n",
    "    def movedown(self):\n",
    "        self.location += 1\n",
    "        \n",
    "    def eat(self, thing):\n",
    "        '''returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Food):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def drink(self, thing):\n",
    "        ''' returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Water):\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time to implement a <b>program</b> module for our dog. A program controls how the dog acts upon its environment. Our program will be very simple, and is shown in the table below.\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><b>Percept:</b> </td>\n",
    "        <td>Feel Food </td>\n",
    "        <td>Feel Water</td>\n",
    "        <td>Feel Nothing</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "       <td><b>Action:</b> </td>\n",
    "       <td>eat</td>\n",
    "       <td>drink</td>\n",
    "       <td>move down</td>\n",
    "   </tr>\n",
    "        \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def program(percepts):\n",
    "    '''Returns an action based on the dog's percepts'''\n",
    "    for p in percepts:\n",
    "        if isinstance(p, Food):\n",
    "            return 'eat'\n",
    "        elif isinstance(p, Water):\n",
    "            return 'drink'\n",
    "    return 'move down'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now run our simulation by creating a park with some food, water, and our dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park = Park()\n",
    "dog = BlindDog(program)\n",
    "dogfood = Food()\n",
    "water = Water()\n",
    "park.add_thing(dog, 1)\n",
    "park.add_thing(dogfood, 5)\n",
    "park.add_thing(water, 7)\n",
    "\n",
    "park.run(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the dog moved from location 1 to 4, over 4 steps, and ate food at location 5 in the 5th step.\n",
    "\n",
    "Let's continue this simulation for 5 more steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park.run(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Note how the simulation stopped after the dog drank the water - exhausting all the food and water ends our simulation, as we had defined before. Let's add some more water and see if our dog can reach it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park.add_thing(water, 15)\n",
    "park.run(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we learnt to implement an agent, its program, and an environment on which it acts. However, this was a very simple case. Let's try to add complexity to it by creating a 2-Dimensional environment!\n",
    "\n",
    "\n",
    "## AGENTS IN A 2D ENVIRONMENT\n",
    "\n",
    "For us to not read so many logs of what our dog did, we add a bit of graphics while making our Park 2D. To do so, we will need to make it a subclass of <b>GraphicEnvironment</b> instead of Environment. Parks implemented by subclassing <b>GraphicEnvironment</b> class adds these extra properties to it:\n",
    "\n",
    " - Our park is indexed in the 4th quadrant of the X-Y plane.\n",
    " - Every time we create a park subclassing <b>GraphicEnvironment</b>, we need to define the colors of all the things we plan to put into the park. The colors are defined in typical [<b>RGB digital 8-bit format</b>](https://en.wikipedia.org/wiki/RGB_color_model#Numeric_representations), common across the web.\n",
    " - Fences are added automatically to all parks so that our dog does not go outside the park's boundary - it just isn't safe for blind dogs to be outside the park by themselves! <b>GraphicEnvironment</b> provides `is_inbounds` function to check if our dog tries to leave the park.\n",
    " \n",
    "First let us try to upgrade our 1-dimensional `Park` environment by just replacing its superclass by `GraphicEnvironment`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Food(Thing):\n",
    "    pass\n",
    "\n",
    "class Water(Thing):\n",
    "    pass\n",
    "\n",
    "class Park2D(GraphicEnvironment):\n",
    "    def percept(self, agent):\n",
    "        '''return a list of things that are in our agent's location'''\n",
    "        things = self.list_things_at(agent.location)\n",
    "        return things\n",
    "    \n",
    "    def execute_action(self, agent, action):\n",
    "        '''changes the state of the environment based on what the agent does.'''\n",
    "        if action == \"move down\":\n",
    "            print('{} decided to {} at location: {}'.format(str(agent)[1:-1], action, agent.location))\n",
    "            agent.movedown()\n",
    "        elif action == \"eat\":\n",
    "            items = self.list_things_at(agent.location, tclass=Food)\n",
    "            if len(items) != 0:\n",
    "                if agent.eat(items[0]): #Have the dog eat the first item\n",
    "                    print('{} ate {} at location: {}'\n",
    "                          .format(str(agent)[1:-1], str(items[0])[1:-1], agent.location))\n",
    "                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "        elif action == \"drink\":\n",
    "            items = self.list_things_at(agent.location, tclass=Water)\n",
    "            if len(items) != 0:\n",
    "                if agent.drink(items[0]): #Have the dog drink the first item\n",
    "                    print('{} drank {} at location: {}'\n",
    "                          .format(str(agent)[1:-1], str(items[0])[1:-1], agent.location))\n",
    "                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "                    \n",
    "    def is_done(self):\n",
    "        '''By default, we're done when we can't find a live agent, \n",
    "        but to prevent killing our cute dog, we will stop before itself - when there is no more food or water'''\n",
    "        no_edibles = not any(isinstance(thing, Food) or isinstance(thing, Water) for thing in self.things)\n",
    "        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "        return dead_agents or no_edibles\n",
    "\n",
    "class BlindDog(Agent):\n",
    "    location = [0,1] # change location to a 2d value\n",
    "    direction = Direction(\"down\") # variable to store the direction our dog is facing\n",
    "    \n",
    "    def movedown(self):\n",
    "        self.location[1] += 1\n",
    "        \n",
    "    def eat(self, thing):\n",
    "        '''returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Food):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def drink(self, thing):\n",
    "        ''' returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Water):\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test this new park with our same dog, food and water. We color our dog with a nice red and mark food and water with orange and blue respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park = Park2D(5,20, color={'BlindDog': (200,0,0), 'Water': (0, 200, 200), 'Food': (230, 115, 40)}) # park width is set to 5, and height to 20\n",
    "dog = BlindDog(program)\n",
    "dogfood = Food()\n",
    "water = Water()\n",
    "park.add_thing(dog, [0,1])\n",
    "park.add_thing(dogfood, [0,5])\n",
    "park.add_thing(water, [0,7])\n",
    "morewater = Water()\n",
    "park.add_thing(morewater, [0,15])\n",
    "print(\"BlindDog starts at (1,1) facing downwards, lets see if he can find any food!\")\n",
    "park.run(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding some graphics was a good idea! We immediately see that the code works, but our blind dog doesn't make any use of the 2 dimensional space available to him. Let's make our dog more energetic so that he turns and moves forward, instead of always moving down. In doing so, we'll also need to make some changes to our environment to be able to handle this extra motion.\n",
    "\n",
    "### PROGRAM - EnergeticBlindDog\n",
    "\n",
    "Let's make our dog turn or move forwards at random - except when he's at the edge of our park - in which case we make him change his direction explicitly by turning to avoid trying to leave the park. However, our dog is blind so he wouldn't know which way to turn - he'd just have to try arbitrarily.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><b>Percept:</b> </td>\n",
    "        <td>Feel Food </td>\n",
    "        <td>Feel Water</td>\n",
    "        <td>Feel Nothing</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "       <td><b>Action:</b> </td>\n",
    "       <td>eat</td>\n",
    "       <td>drink</td>\n",
    "       <td>\n",
    "       <table>\n",
    "           <tr>\n",
    "               <td><b>Remember being at Edge : </b></td>\n",
    "               <td>At Edge</td>\n",
    "               <td>Not at Edge</td>\n",
    "           </tr>\n",
    "           <tr>\n",
    "               <td><b>Action : </b></td>\n",
    "               <td>Turn Left / Turn Right <br> ( 50% - 50% chance )</td>\n",
    "               <td>Turn Left / Turn Right / Move Forward <br> ( 25% - 25% - 50% chance )</td>\n",
    "           </tr>\n",
    "       </table>\n",
    "       </td>\n",
    "   </tr>\n",
    "        \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "class EnergeticBlindDog(Agent):\n",
    "    location = [0,1]\n",
    "    direction = Direction(\"down\")\n",
    "    \n",
    "    def moveforward(self, success=True):\n",
    "        '''moveforward possible only if success (i.e. valid destination location)'''\n",
    "        if not success:\n",
    "            return\n",
    "        if self.direction.direction == Direction.R:\n",
    "            self.location[0] += 1\n",
    "        elif self.direction.direction == Direction.L:\n",
    "            self.location[0] -= 1\n",
    "        elif self.direction.direction == Direction.D:\n",
    "            self.location[1] += 1\n",
    "        elif self.direction.direction == Direction.U:\n",
    "            self.location[1] -= 1\n",
    "    \n",
    "    def turn(self, d):\n",
    "        self.direction = self.direction + d\n",
    "        \n",
    "    def eat(self, thing):\n",
    "        '''returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Food):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def drink(self, thing):\n",
    "        ''' returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Water):\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "def program(percepts):\n",
    "    '''Returns an action based on it's percepts'''\n",
    "        \n",
    "    for p in percepts: # first eat or drink - you're a dog!\n",
    "        if isinstance(p, Food):\n",
    "            return 'eat'\n",
    "        elif isinstance(p, Water):\n",
    "            return 'drink'\n",
    "        if isinstance(p,Bump): # then check if you are at an edge and have to turn\n",
    "            turn = False\n",
    "            choice = random.choice((1,2));\n",
    "        else:\n",
    "            choice = random.choice((1,2,3,4)) # 1-right, 2-left, others-forward\n",
    "    if choice == 1:\n",
    "        return 'turnright'\n",
    "    elif choice == 2:\n",
    "        return 'turnleft'\n",
    "    else:\n",
    "        return 'moveforward'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENVIRONMENT - Park2D\n",
    "\n",
    "We also need to modify our park accordingly, in order to be able to handle all the new actions our dog wishes to execute. Additionally, we'll need to prevent our dog from moving to locations beyond our park boundary - it just isn't safe for blind dogs to be outside the park by themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Park2D(GraphicEnvironment):\n",
    "    def percept(self, agent):\n",
    "        '''return a list of things that are in our agent's location'''\n",
    "        things = self.list_things_at(agent.location)\n",
    "        loc = copy.deepcopy(agent.location) # find out the target location\n",
    "        #Check if agent is about to bump into a wall\n",
    "        if agent.direction.direction == Direction.R:\n",
    "            loc[0] += 1\n",
    "        elif agent.direction.direction == Direction.L:\n",
    "            loc[0] -= 1\n",
    "        elif agent.direction.direction == Direction.D:\n",
    "            loc[1] += 1\n",
    "        elif agent.direction.direction == Direction.U:\n",
    "            loc[1] -= 1\n",
    "        if not self.is_inbounds(loc):\n",
    "            things.append(Bump())\n",
    "        return things\n",
    "    \n",
    "    def execute_action(self, agent, action):\n",
    "        '''changes the state of the environment based on what the agent does.'''\n",
    "        if action == 'turnright':\n",
    "            print('{} decided to {} at location: {}'.format(str(agent)[1:-1], action, agent.location))\n",
    "            agent.turn(Direction.R)\n",
    "        elif action == 'turnleft':\n",
    "            print('{} decided to {} at location: {}'.format(str(agent)[1:-1], action, agent.location))\n",
    "            agent.turn(Direction.L)\n",
    "        elif action == 'moveforward':\n",
    "            print('{} decided to move {}wards at location: {}'.format(str(agent)[1:-1], agent.direction.direction, agent.location))\n",
    "            agent.moveforward()\n",
    "        elif action == \"eat\":\n",
    "            items = self.list_things_at(agent.location, tclass=Food)\n",
    "            if len(items) != 0:\n",
    "                if agent.eat(items[0]):\n",
    "                    print('{} ate {} at location: {}'\n",
    "                          .format(str(agent)[1:-1], str(items[0])[1:-1], agent.location))\n",
    "                    self.delete_thing(items[0])\n",
    "        elif action == \"drink\":\n",
    "            items = self.list_things_at(agent.location, tclass=Water)\n",
    "            if len(items) != 0:\n",
    "                if agent.drink(items[0]):\n",
    "                    print('{} drank {} at location: {}'\n",
    "                          .format(str(agent)[1:-1], str(items[0])[1:-1], agent.location))\n",
    "                    self.delete_thing(items[0])\n",
    "                    \n",
    "    def is_done(self):\n",
    "        '''By default, we're done when we can't find a live agent, \n",
    "        but to prevent killing our cute dog, we will stop before itself - when there is no more food or water'''\n",
    "        no_edibles = not any(isinstance(thing, Food) or isinstance(thing, Water) for thing in self.things)\n",
    "        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "        return dead_agents or no_edibles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our park is ready for the 2D motion of our energetic dog, lets test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park = Park2D(5,5, color={'EnergeticBlindDog': (200,0,0), 'Water': (0, 200, 200), 'Food': (230, 115, 40)})\n",
    "dog = EnergeticBlindDog(program)\n",
    "dogfood = Food()\n",
    "water = Water()\n",
    "park.add_thing(dog, [0,0])\n",
    "park.add_thing(dogfood, [1,2])\n",
    "park.add_thing(water, [0,1])\n",
    "morewater = Water()\n",
    "morefood = Food()\n",
    "park.add_thing(morewater, [2,4])\n",
    "park.add_thing(morefood, [4,3])\n",
    "print(\"dog started at [0,0], facing down. Let's see if he found any food or water!\")\n",
    "park.run(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "- Run and understand all the code above for the blind dog and the energetic blind dog.\n",
    "- Make the following changes in the code above:\n",
    "    1. Add a third percept \"Bone\"\n",
    "    2. After having eaten and drank water twice, move the dog to find the bone. The dog plays with it happily ever after!\n",
    "    4. Add food and water at [0, 11] and [0, 14], respectively\n",
    "    3. Add bone at [0, 19] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your changes for exercise 2 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park = Park2D(5,20, color={'BlindDog': (200,0,0), 'Water': (0, 200, 200), 'Food': (230, 115, 40)}) # park width is set to 5, and height to 20\n",
    "dog = BlindDog(program)\n",
    "dogfood = Food()\n",
    "water = Water()\n",
    "park.add_thing(dog, [0,1])\n",
    "park.add_thing(dogfood, [0,5])\n",
    "park.add_thing(water, [0,7])\n",
    "morewater = Water()\n",
    "park.add_thing(morewater, [0,15])\n",
    "print(\"BlindDog starts at (1,1) facing downwards, lets see if he can find any food!\")\n",
    "park.run(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park = Park2D(5,5, color={'EnergeticBlindDog': (200,0,0), 'Water': (0, 200, 200), 'Food': (230, 115, 40)}) # You might need to change the park size\n",
    "dog = EnergeticBlindDog(program)\n",
    "dogfood = Food()\n",
    "water = Water()\n",
    "park.add_thing(dog, [0,0])\n",
    "park.add_thing(dogfood, [1,2])\n",
    "park.add_thing(water, [0,1])\n",
    "morewater = Water()\n",
    "morefood = Food()\n",
    "park.add_thing(morewater, [2,4])\n",
    "park.add_thing(morefood, [4,3])\n",
    "print(\"dog started at [0,0], facing down. Let's see if he found any food or water!\")\n",
    "park.run(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Happy Dog](https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExemw5ODVtZG5yY2xicm1lYjExNHI3NDA1cGxpbXp4MGp3aXlpeGIwNiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/1Ju5mGZlWAqek/giphy.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
